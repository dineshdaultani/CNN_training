{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "ResNet_empty.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshdaultani/CNN_training/blob/master/notebooks/2020_07_25_final/ResNet_empty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe_8aJLOFM2p",
        "colab_type": "text"
      },
      "source": [
        "### This notebook is a tutorial for how to train a ResNet model on Signs dataset.  \n",
        "\n",
        "### References:\n",
        "Code: https://github.com/marcopeix/Deep_Learning_AI/tree/master/4.Convolutional%20Neural%20Networks   \n",
        "ResNet blocks images: https://medium.com/analytics-vidhya/understanding-and-implementation-of-residual-networks-resnets-b80f9a507b9c  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UckORy8mWxTl",
        "colab_type": "text"
      },
      "source": [
        "### Let's start with importing relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4n0Km9bFLzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b30afa9-6ec5-4710-c66b-900e3465f1ed"
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "# import keras.backend as K\n",
        "# K.set_image_data_format('channels_last')\n",
        "# K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pqo2yd7N8o7",
        "colab_type": "text"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwnBIT2rUjD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import math\n",
        "import urllib.request\n",
        "\n",
        "def load_dataset():\n",
        "    urllib.request.urlretrieve('https://drive.google.com/u/0/uc?id=1uOOg-YDFjyTlJC1-khplcxBInKDEnH5D&export=download', '/content/train_signs.h5')\n",
        "    train_dataset = h5py.File('/content/train_signs.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "    print(\"Train data loaded\")\n",
        "\n",
        "    urllib.request.urlretrieve('https://drive.google.com/u/0/uc?id=1C9KqEWm59Hfiaco3lFQ2zZldJFb00zRt&export=download', '/content/test_signs.h5')\n",
        "    test_dataset = h5py.File('/content/test_signs.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "    print(\"Test data loaded\")\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ8MAGd-N-f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_TR5CmnV4sp",
        "colab_type": "text"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1XcHNugDP6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf2z8arK8_9D",
        "colab_type": "text"
      },
      "source": [
        "# Let's visualize some training examples and their labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s33LgBeLDRGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJgoWWVxV-f7",
        "colab_type": "text"
      },
      "source": [
        "# Defining the architecture of the ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44XK6xAIAWPv",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/u/0/uc?id=1i9zEzdzjLsI-QvV5NFIDTsNhfs-sHxbS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP1YFvsK9FC4",
        "colab_type": "text"
      },
      "source": [
        "## Identity Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXQAJ64_6gH6",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1400/1*BCbJZXwGDtEdytj9ag_YWw.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p27tmfiQn6Uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in in above figure\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1rV9Kcc9If_",
        "colab_type": "text"
      },
      "source": [
        "## Convolution Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZQ58DY25szR",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/1400/1*sb_4xKI_bRoX6jmZcNTRWw.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq_aWrKIn9l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in above figure\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOy9_6O-oSm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poi6H3wgob_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUHU55KT7I7S",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### We will **compile** our model by defining loss, optimizer and metrics that we will use to train our network.\n",
        "* loss: [categorical_crossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-function)\n",
        "* optimizer: [adam](https://keras.io/api/optimizers/adam/)\n",
        "* metrics: [accuracy](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNSv4vCKoeQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk6TpnarOS9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hk-Wfvk7eLi",
        "colab_type": "text"
      },
      "source": [
        "### Now, let's **train our model** by using the parameters that we defined before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YET2uD_DrwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHeBGU887kjQ",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluation** of the trained model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcE0dygzDd5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNPpfTvQoo1w",
        "colab_type": "text"
      },
      "source": [
        "## Pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmlXjqC9UJTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install gdown\n",
        "import gdown\n",
        "if 'ResNet50.h5' not in os.listdir('/content/'):\n",
        "  gdown.download('https://drive.google.com/uc?id=14vW8s9Os7zXGeixXvMO9S1QoHBPM5MPx', '/content/ResNet50.h5', quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUuQYuX_U_xR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU6nuKIYDkxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFsMX-94-7rG",
        "colab_type": "text"
      },
      "source": [
        "## Let's visualize the correctly classified images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By9UkjJC987j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dOHipQy9_nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBPnWEZFP14F",
        "colab_type": "text"
      },
      "source": [
        "### How about we **visualize images that our model predicted incorrectly**.  \n",
        "*   First we have to get the indexes of the images where y_pred and y_test doesn't match\n",
        "*   Then we can visualize them one by one\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UikY7W-bDpex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}