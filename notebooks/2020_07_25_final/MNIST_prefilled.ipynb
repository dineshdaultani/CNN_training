{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "MNIST_prefilled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshdaultani/CNN_training/blob/master/notebooks/2020_07_25_final/MNIST_prefilled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe_8aJLOFM2p",
        "colab_type": "text"
      },
      "source": [
        "### This notebook is a tutorial for how to train a CNN model on MNIST dataset.  \n",
        "### MNIST contains pictures of handwritten digits. \n",
        "\n",
        "### References:\n",
        "Code: https://keras.io/examples/mnist_cnn/  \n",
        "MNIST: http://yann.lecun.com/exdb/mnist/  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UckORy8mWxTl",
        "colab_type": "text"
      },
      "source": [
        "### Let's start with importing relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4n0Km9bFLzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c39ff0a2-1221-4407-ec93-0dd6a1b4c365"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_8G01IbPFSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWRZzu0W3O5",
        "colab_type": "text"
      },
      "source": [
        "### **Load the MNIST dataset** from inbuilt keras function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXaVDs3zW_Az",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d5651058-ff32-47a6-e103-34467f7a7fe9"
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8RldXndWych",
        "colab_type": "text"
      },
      "source": [
        "### **Visualize data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZwnmcDOWuOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "c7ce6c7d-8c08-4cc4-ab7e-d3b098a744f0"
      },
      "source": [
        "nth_img = 0\n",
        "print('label: ' + str(y_train[nth_img]))\n",
        "plt.imshow(x_train[nth_img].reshape((28, 28)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3094aa40b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CzquW9NXVIt",
        "colab_type": "text"
      },
      "source": [
        "### We will initialize some parameters that we would be using later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phSis5nRH3JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quy74gVaIAjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9cvZjzkXeky",
        "colab_type": "text"
      },
      "source": [
        "### **Preprocessing the images**\n",
        "* Format the training and testing images data to float32. \n",
        "* Next we will **normalize** each pixel by dividing 255. Now each pixel will be in range [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RAxB0lNIBL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J68Z-O-yYCsA",
        "colab_type": "text"
      },
      "source": [
        "### **Preprocessing the labels**\n",
        "* We will use inbuilt [to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) function to convert labels to one-hot encoding vector \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Iw8xADIiAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f7RYTZ8QXoy",
        "colab_type": "text"
      },
      "source": [
        "### **Designing the model**\n",
        "Let's create a [sequential](https://keras.io/api/models/sequential/) model in keras. Architecture of our model is going to look like as follows:\n",
        "\n",
        "1. [**Conv2D layer**](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
        "  * With 32 filters and kernel size (3,3) and relu activation\n",
        "2. **Conv2D layer**\n",
        "  * With 64 filters and kernel size (3,3) and relu activation\n",
        "3. [**MaxPooling2D layer**](https://keras.io/api/layers/pooling_layers/max_pooling2d/)\n",
        "  * With pool_size (2,2)\n",
        "4. [**Flatten** ](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
        "5. [**Dense**](https://keras.io/api/layers/core_layers/dense/) with 128 neurons and relu activation\n",
        "6. [**Dropout**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) (optional)\n",
        "7. Last **Dense** layer with **softmax** activations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1FAlSSAIBTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SsPw0qmZBe9",
        "colab_type": "text"
      },
      "source": [
        "### We will **compile** our model by defining loss, optimizer and metrics that we will use to train our network.\n",
        "* loss: [categorical_crossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-function)\n",
        "* optimizer: [Adadelta](https://keras.io/api/optimizers/adadelta/)\n",
        "* metrics: [accuracy](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wolqag-DIBYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-i5cxncWiKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "af33dae9-e7ab-4db6-f54d-c9486f3d4fae"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT8QUOzeaM9g",
        "colab_type": "text"
      },
      "source": [
        "### Now, let's **train our model** by using the parameters that we defined before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pYF0BnzIa-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "072c749d-dbfc-4c8d-b5d2-85021c516707"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 0.2711 - accuracy: 0.9162 - val_loss: 0.0588 - val_accuracy: 0.9811\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0896 - accuracy: 0.9740 - val_loss: 0.0376 - val_accuracy: 0.9883\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.0659 - accuracy: 0.9802 - val_loss: 0.0369 - val_accuracy: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0540 - accuracy: 0.9841 - val_loss: 0.0327 - val_accuracy: 0.9890\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.0286 - val_accuracy: 0.9904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f30949f6080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhKxXp71aYk6",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluation** of the trained model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTdR1x4-IbXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b2b8e5d-b224-4beb-f2fa-da889f1f88d8"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.028583086468774853\n",
            "Test accuracy: 0.9904000163078308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1rAqQMCasTL",
        "colab_type": "text"
      },
      "source": [
        "### We can **visualize or analyze our model** to see how our predictions looks like. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUG4_UFpNCru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSZyeiwWOCeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_labels = np.argmax(y_pred, axis = 1)\n",
        "y_test_labels = np.argmax(y_test, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AwLBc8FLvQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "b7ac008b-b2e4-4eac-86a6-09ff15593c1f"
      },
      "source": [
        "nth_img = 1001\n",
        "print('actual_label: '  + str(y_test_labels[nth_img]))\n",
        "print('predicted_label: '  + str(y_pred_labels[nth_img]))\n",
        "plt.imshow(x_test[nth_img].reshape((28, 28)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual_label: 0\n",
            "predicted_label: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3038046358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBPnWEZFP14F",
        "colab_type": "text"
      },
      "source": [
        "### How about we **visualize images that our model predicted incorrectly**.  \n",
        "*   First we have to get the indexes of the images where y_pred and y_test doesn't match\n",
        "*   Then we can visualize them one by one\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFK8YVnMQTLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "faaba246-72b2-45ce-9322-1c102c57d440"
      },
      "source": [
        "np.where(y_pred_labels != y_test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 247,  320,  321,  445,  449,  659,  717,  740,  882,  947, 1014,\n",
              "        1033, 1039, 1112, 1226, 1232, 1242, 1247, 1260, 1319, 1393, 1527,\n",
              "        1530, 1549, 1621, 1681, 1709, 1717, 1878, 1901, 2035, 2040, 2098,\n",
              "        2118, 2130, 2135, 2293, 2369, 2387, 2406, 2462, 2488, 2630, 2654,\n",
              "        2896, 2921, 2927, 2939, 3030, 3060, 3073, 3225, 3384, 3422, 3503,\n",
              "        3520, 3558, 3727, 3767, 3780, 3808, 3941, 4007, 4078, 4176, 4238,\n",
              "        4248, 4256, 4497, 4639, 4731, 4740, 4761, 4807, 4860, 5937, 5955,\n",
              "        6091, 6576, 6597, 6625, 6651, 6783, 8094, 8325, 8527, 9009, 9015,\n",
              "        9019, 9530, 9642, 9664, 9692, 9729, 9770, 9982]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oJ2q84WPytr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "0fc00fed-4562-4593-d25c-8f7e8c0f950f"
      },
      "source": [
        "nth_img = 321\n",
        "print('actual_label: '  + str(y_test_labels[nth_img]))\n",
        "print('predicted_label: '  + str(y_pred_labels[nth_img]))\n",
        "plt.imshow(x_test[nth_img].reshape((28, 28)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual_label: 2\n",
            "predicted_label: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f30227e6908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umFfvrJ3NY7B",
        "colab_type": "text"
      },
      "source": [
        "***Want to try something more on other small datasets?***\n",
        "*   https://keras.io/api/datasets/  (Contains **CIFAR** and **Fashion MNIST** dataset)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}