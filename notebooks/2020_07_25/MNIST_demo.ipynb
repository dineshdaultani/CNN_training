{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "MNIST demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshdaultani/CNN_training/blob/master/notebooks/2020_07_25/MNIST_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe_8aJLOFM2p",
        "colab_type": "text"
      },
      "source": [
        "### This notebook is a tutorial for how to train a CNN model on MNIST dataset. MNIST contains pictures of handwritten digits. \n",
        "\n",
        "### References:\n",
        "Code: https://keras.io/examples/mnist_cnn/  \n",
        "MNIST: http://yann.lecun.com/exdb/mnist/  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UckORy8mWxTl",
        "colab_type": "text"
      },
      "source": [
        "### Let's start with importing relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4n0Km9bFLzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "998de30d-ce0d-495e-e19b-465ebcaf9b96"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_8G01IbPFSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWRZzu0W3O5",
        "colab_type": "text"
      },
      "source": [
        "### **Load the MNIST dataset** from inbuilt keras function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXaVDs3zW_Az",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c5f1c104-cb76-44d9-ffda-75b64e9d57f5"
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CzquW9NXVIt",
        "colab_type": "text"
      },
      "source": [
        "### We will initialize some parameters that we would be using later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phSis5nRH3JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quy74gVaIAjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9cvZjzkXeky",
        "colab_type": "text"
      },
      "source": [
        "### **Preprocessing the images**\n",
        "* Format the training and testing images data to float32. \n",
        "* Next we will **normalize** each pixel by dividing 255. Now each pixel will be in range [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RAxB0lNIBL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J68Z-O-yYCsA",
        "colab_type": "text"
      },
      "source": [
        "### **Preprocessing the labels**\n",
        "* We will use inbuilt [to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) function to convert labels to one-hot encoding vector \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Iw8xADIiAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f7RYTZ8QXoy",
        "colab_type": "text"
      },
      "source": [
        "### **Designing the model**\n",
        "Let's create a [sequential](https://keras.io/api/models/sequential/) model in keras. Architecture of our model is going to look like as follows:\n",
        "\n",
        "1. [**Conv2D layer**](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
        "  * With 32 filters and kernel size (3,3) and relu activation\n",
        "2. **Conv2D layer**\n",
        "  * With 64 filters and kernel size (3,3) and relu activation\n",
        "3. [**MaxPooling2D layer**](https://keras.io/api/layers/pooling_layers/max_pooling2d/)\n",
        "  * With pool_size (2,2)\n",
        "4. [**Flatten** ](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
        "5. [**Dense**](https://keras.io/api/layers/core_layers/dense/) with 128 neurons and relu activation\n",
        "6. [**Dropout**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) (optional)\n",
        "7. Last **Dense** layer with **softmax** activations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1FAlSSAIBTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SsPw0qmZBe9",
        "colab_type": "text"
      },
      "source": [
        "### We will **compile** our model by defining loss, optimizer and metrics that we will use to train our network.\n",
        "* loss: [categorical_crossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-function)\n",
        "* optimizer: [Adadelta](https://keras.io/api/optimizers/adadelta/)\n",
        "* metrics: [accuracy](https://keras.io/api/metrics/accuracy_metrics/#accuracy-class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wolqag-DIBYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT8QUOzeaM9g",
        "colab_type": "text"
      },
      "source": [
        "### Now, let's **train our model** by using the parameters that we defined before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pYF0BnzIa-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ce415dd7-2594-4029-f590-c3a0130288b3"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.2521 - accuracy: 0.9229 - val_loss: 0.0581 - val_accuracy: 0.9818\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 142us/step - loss: 0.0842 - accuracy: 0.9745 - val_loss: 0.0444 - val_accuracy: 0.9851\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.0362 - val_accuracy: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.0332 - val_accuracy: 0.9884\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.0280 - val_accuracy: 0.9906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f10a0692898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhKxXp71aYk6",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluation** of the trained model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTdR1x4-IbXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e76cb3c0-f096-40da-c1d7-2f263c996cda"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.027999724970491663\n",
            "Test accuracy: 0.9905999898910522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1rAqQMCasTL",
        "colab_type": "text"
      },
      "source": [
        "### We can **visualize or analyze our model** to see how our predictions looks like. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUG4_UFpNCru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSZyeiwWOCeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_labels = np.argmax(y_pred, axis = 1)\n",
        "y_test_labels = np.argmax(y_test, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AwLBc8FLvQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "e075b979-141d-4950-defd-fb24934d3665"
      },
      "source": [
        "nth_img = 1001\n",
        "print('actual_label: '  + str(y_test_labels[nth_img]))\n",
        "print('predicted_label: '  + str(y_pred_labels[nth_img]))\n",
        "plt.imshow(x_test[nth_img].reshape((28, 28)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual_label: 0\n",
            "predicted_label: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f10a04d37b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBPnWEZFP14F",
        "colab_type": "text"
      },
      "source": [
        "### How about we **visualize images that our model predicted incorrectly**.  \n",
        "*   First we have to get the indexes of the images where y_pred and y_test doesn't match\n",
        "*   Then we can visualize them one by one\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFK8YVnMQTLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a058463a-7b3b-4ae9-bc56-e20ff1c29071"
      },
      "source": [
        "np.where(y_pred_labels != y_test_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 247,  259,  321,  340,  445,  449,  582,  740,  844,  938,  947,\n",
              "        1014, 1039, 1112, 1226, 1232, 1242, 1247, 1260, 1319, 1414, 1522,\n",
              "        1530, 1549, 1621, 1681, 1709, 1717, 1901, 2035, 2040, 2043, 2070,\n",
              "        2118, 2130, 2135, 2293, 2406, 2454, 2462, 2597, 2654, 2896, 2921,\n",
              "        2927, 2939, 3030, 3060, 3289, 3422, 3520, 3534, 3558, 3726, 3749,\n",
              "        3767, 3796, 3808, 3941, 4007, 4163, 4176, 4248, 4256, 4536, 4571,\n",
              "        4639, 4731, 4740, 4761, 4807, 4814, 4823, 4860, 5937, 5955, 6091,\n",
              "        6505, 6555, 6597, 6625, 6651, 6755, 8408, 8527, 9009, 9015, 9019,\n",
              "        9642, 9664, 9692, 9729, 9770, 9982]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oJ2q84WPytr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "b2ac5c25-2357-4885-bbca-0cc48d61fc96"
      },
      "source": [
        "nth_img = 321\n",
        "print('actual_label: '  + str(y_test_labels[nth_img]))\n",
        "print('predicted_label: '  + str(y_pred_labels[nth_img]))\n",
        "plt.imshow(x_test[nth_img].reshape((28, 28)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual_label: 2\n",
            "predicted_label: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f10560a6da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umFfvrJ3NY7B",
        "colab_type": "text"
      },
      "source": [
        "***Want to try something more on other small datasets?***\n",
        "*   https://keras.io/api/datasets/  (Contains **CIFAR** and **Fashion MNIST** dataset)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}